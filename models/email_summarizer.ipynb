{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the local file\n",
    "file_path = \"/Users/owendolan/Desktop/nlp-email-client/data/article_summaries(small).csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract documents (Content) and summaries\n",
    "articles = data[\"Content\"].astype(str).tolist()\n",
    "summaries = data[\"Summary\"].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "max_vocab_size = 2000\n",
    "max_seq_length = 20\n",
    "\n",
    "# Create and configure tokenizers with special tokens\n",
    "input_tokenizer = Tokenizer(num_words=max_vocab_size, oov_token=\"<unk>\")\n",
    "target_tokenizer = Tokenizer(num_words=max_vocab_size, oov_token=\"<unk>\")\n",
    "\n",
    "# Add special tokens to target texts\n",
    "target_texts_with_tokens = ['<start> ' + text + ' <end>' for text in summaries]\n",
    "\n",
    "# Fit tokenizers\n",
    "input_tokenizer.fit_on_texts(articles)\n",
    "target_tokenizer.fit_on_texts(target_texts_with_tokens)\n",
    "\n",
    "# Manually add special tokens if they're not in the vocabulary\n",
    "special_tokens = ['<start>', '<end>', '<unk>']\n",
    "current_index = len(target_tokenizer.word_index) + 1\n",
    "for token in special_tokens:\n",
    "    if token not in target_tokenizer.word_index:\n",
    "        target_tokenizer.word_index[token] = current_index\n",
    "        target_tokenizer.index_word[current_index] = token\n",
    "        current_index += 1\n",
    "\n",
    "# Tokenize texts\n",
    "input_sequences = input_tokenizer.texts_to_sequences(articles)\n",
    "target_sequences = target_tokenizer.texts_to_sequences(target_texts_with_tokens)\n",
    "\n",
    "# Pad sequences\n",
    "encoder_input_data = pad_sequences(input_sequences, maxlen=max_seq_length, padding='post')\n",
    "decoder_input_data = pad_sequences(target_sequences, maxlen=max_seq_length, padding='post')\n",
    "\n",
    "# Prepare decoder target data (shifted by one timestep)\n",
    "decoder_target_data = np.zeros_like(decoder_input_data)\n",
    "decoder_target_data[:, :-1] = decoder_input_data[:, 1:]\n",
    "\n",
    "# Update max_vocab_size to account for special tokens\n",
    "max_vocab_size = max(len(input_tokenizer.word_index) + 1, len(target_tokenizer.word_index) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 16:25:59.240156: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-11-15 16:25:59.240186: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-11-15 16:25:59.240195: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-11-15 16:25:59.240215: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-11-15 16:25:59.240229: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Model architecture\n",
    "embedding_dim = 256\n",
    "lstm_units = 256\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_seq_length,))\n",
    "encoder_embedding = Embedding(input_dim=max_vocab_size, output_dim=embedding_dim, mask_zero=True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(lstm_units, return_state=True)\n",
    "_, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_seq_length,))\n",
    "decoder_embedding = Embedding(input_dim=max_vocab_size, output_dim=embedding_dim, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(max_vocab_size, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Combined Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owendolan/opt/miniconda3/envs/neural-env/lib/python3.10/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor', 'keras_tensor_6']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n",
      "2024-11-15 16:26:00.596838: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 256ms/step - accuracy: 0.1735 - loss: 10.0380 - val_accuracy: 0.2175 - val_loss: 6.5481\n",
      "Epoch 2/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 209ms/step - accuracy: 0.2112 - loss: 5.7711 - val_accuracy: 0.2271 - val_loss: 5.5520\n",
      "Epoch 3/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 207ms/step - accuracy: 0.2198 - loss: 5.1458 - val_accuracy: 0.2271 - val_loss: 5.4617\n",
      "Epoch 4/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 209ms/step - accuracy: 0.2196 - loss: 5.0522 - val_accuracy: 0.2271 - val_loss: 5.4066\n",
      "Epoch 5/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 207ms/step - accuracy: 0.2201 - loss: 5.0029 - val_accuracy: 0.2271 - val_loss: 5.3706\n",
      "Epoch 6/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 207ms/step - accuracy: 0.2187 - loss: 5.0015 - val_accuracy: 0.2271 - val_loss: 5.3333\n",
      "Epoch 7/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 208ms/step - accuracy: 0.2446 - loss: 4.9834 - val_accuracy: 0.3041 - val_loss: 5.3096\n",
      "Epoch 8/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 207ms/step - accuracy: 0.2957 - loss: 4.9274 - val_accuracy: 0.3108 - val_loss: 5.2679\n",
      "Epoch 9/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 206ms/step - accuracy: 0.2990 - loss: 4.9063 - val_accuracy: 0.3115 - val_loss: 5.2401\n",
      "Epoch 10/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 209ms/step - accuracy: 0.3005 - loss: 4.8569 - val_accuracy: 0.3099 - val_loss: 5.1980\n",
      "Epoch 11/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 207ms/step - accuracy: 0.2998 - loss: 4.8182 - val_accuracy: 0.3057 - val_loss: 5.1780\n",
      "Epoch 12/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 207ms/step - accuracy: 0.3033 - loss: 4.7411 - val_accuracy: 0.3083 - val_loss: 5.1649\n",
      "Epoch 13/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.2919 - loss: 4.7932 - val_accuracy: 0.3061 - val_loss: 5.1576\n",
      "Epoch 14/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 209ms/step - accuracy: 0.2955 - loss: 4.7754 - val_accuracy: 0.3089 - val_loss: 5.1600\n",
      "Epoch 15/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 209ms/step - accuracy: 0.2967 - loss: 4.7173 - val_accuracy: 0.3080 - val_loss: 5.1483\n",
      "Epoch 16/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 209ms/step - accuracy: 0.2961 - loss: 4.7324 - val_accuracy: 0.3080 - val_loss: 5.1533\n",
      "Epoch 17/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 207ms/step - accuracy: 0.2952 - loss: 4.7106 - val_accuracy: 0.3105 - val_loss: 5.1463\n",
      "Epoch 18/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 209ms/step - accuracy: 0.2967 - loss: 4.6737 - val_accuracy: 0.3127 - val_loss: 5.1426\n",
      "Epoch 19/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 207ms/step - accuracy: 0.3065 - loss: 4.6000 - val_accuracy: 0.3137 - val_loss: 5.1450\n",
      "Epoch 20/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 209ms/step - accuracy: 0.3102 - loss: 4.5519 - val_accuracy: 0.3118 - val_loss: 5.1453\n",
      "Epoch 21/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 208ms/step - accuracy: 0.3022 - loss: 4.6107 - val_accuracy: 0.3061 - val_loss: 5.1631\n",
      "Epoch 22/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 208ms/step - accuracy: 0.3002 - loss: 4.5988 - val_accuracy: 0.3051 - val_loss: 5.1591\n",
      "Epoch 23/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 208ms/step - accuracy: 0.3068 - loss: 4.5007 - val_accuracy: 0.3057 - val_loss: 5.1518\n",
      "Epoch 24/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 208ms/step - accuracy: 0.3107 - loss: 4.4739 - val_accuracy: 0.3061 - val_loss: 5.1586\n",
      "Epoch 25/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 208ms/step - accuracy: 0.3097 - loss: 4.4272 - val_accuracy: 0.3061 - val_loss: 5.1554\n",
      "Epoch 26/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.3077 - loss: 4.4229 - val_accuracy: 0.3080 - val_loss: 5.1728\n",
      "Epoch 27/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 208ms/step - accuracy: 0.3173 - loss: 4.3502 - val_accuracy: 0.3029 - val_loss: 5.1721\n",
      "Epoch 28/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 217ms/step - accuracy: 0.3064 - loss: 4.3791 - val_accuracy: 0.3010 - val_loss: 5.1849\n",
      "Epoch 29/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 211ms/step - accuracy: 0.3162 - loss: 4.3085 - val_accuracy: 0.3045 - val_loss: 5.1863\n",
      "Epoch 30/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 219ms/step - accuracy: 0.3140 - loss: 4.2966 - val_accuracy: 0.2962 - val_loss: 5.2301\n",
      "Epoch 31/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 214ms/step - accuracy: 0.3085 - loss: 4.3171 - val_accuracy: 0.3016 - val_loss: 5.2195\n",
      "Epoch 32/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 215ms/step - accuracy: 0.3224 - loss: 4.2513 - val_accuracy: 0.3010 - val_loss: 5.2112\n",
      "Epoch 33/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 214ms/step - accuracy: 0.3142 - loss: 4.2381 - val_accuracy: 0.3022 - val_loss: 5.2203\n",
      "Epoch 34/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.3194 - loss: 4.1992 - val_accuracy: 0.3013 - val_loss: 5.2332\n",
      "Epoch 35/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 212ms/step - accuracy: 0.3209 - loss: 4.1685 - val_accuracy: 0.3057 - val_loss: 5.2317\n",
      "Epoch 36/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 212ms/step - accuracy: 0.3231 - loss: 4.1562 - val_accuracy: 0.3032 - val_loss: 5.2418\n",
      "Epoch 37/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.3272 - loss: 4.1045 - val_accuracy: 0.3051 - val_loss: 5.2400\n",
      "Epoch 38/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 211ms/step - accuracy: 0.3240 - loss: 4.0862 - val_accuracy: 0.3038 - val_loss: 5.2450\n",
      "Epoch 39/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 216ms/step - accuracy: 0.3267 - loss: 4.0483 - val_accuracy: 0.3035 - val_loss: 5.2541\n",
      "Epoch 40/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.3254 - loss: 4.0266 - val_accuracy: 0.3035 - val_loss: 5.2584\n",
      "Epoch 41/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.3272 - loss: 4.0077 - val_accuracy: 0.3035 - val_loss: 5.2678\n",
      "Epoch 42/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 209ms/step - accuracy: 0.3362 - loss: 3.9500 - val_accuracy: 0.3029 - val_loss: 5.2803\n",
      "Epoch 43/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 208ms/step - accuracy: 0.3280 - loss: 3.9319 - val_accuracy: 0.3064 - val_loss: 5.2759\n",
      "Epoch 44/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 211ms/step - accuracy: 0.3362 - loss: 3.9212 - val_accuracy: 0.3080 - val_loss: 5.2924\n",
      "Epoch 45/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.3260 - loss: 3.9233 - val_accuracy: 0.3086 - val_loss: 5.2921\n",
      "Epoch 46/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 209ms/step - accuracy: 0.3334 - loss: 3.8698 - val_accuracy: 0.3086 - val_loss: 5.2951\n",
      "Epoch 47/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 208ms/step - accuracy: 0.3381 - loss: 3.8254 - val_accuracy: 0.3022 - val_loss: 5.3109\n",
      "Epoch 48/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 213ms/step - accuracy: 0.3434 - loss: 3.7849 - val_accuracy: 0.2990 - val_loss: 5.3162\n",
      "Epoch 49/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.3375 - loss: 3.7955 - val_accuracy: 0.3080 - val_loss: 5.3229\n",
      "Epoch 50/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 210ms/step - accuracy: 0.3513 - loss: 3.7229 - val_accuracy: 0.3019 - val_loss: 5.3341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x15bc35150>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model \n",
    "\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    np.expand_dims(decoder_target_data, -1),\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Model\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder Model\n",
    "decoder_state_input_h = Input(shape=(lstm_units,))\n",
    "decoder_state_input_c = Input(shape=(lstm_units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_lstm_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_embedding, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_lstm_outputs)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input sequence\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Verify that '<start>' is in the vocabulary\n",
    "    if '<start>' not in target_tokenizer.word_index:\n",
    "        raise KeyError(\"'<start>' token not found in vocabulary!\")\n",
    "        \n",
    "    # Generate empty target sequence with <start> token\n",
    "    target_seq = np.zeros((1, max_seq_length))\n",
    "    target_seq[0, 0] = target_tokenizer.word_index['<start>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = []\n",
    "    iteration = 0  # for debugging loop iterations\n",
    "    \n",
    "    while not stop_condition:\n",
    "        # Predict the next word\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        # Get the predicted word\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = target_tokenizer.index_word.get(sampled_token_index, '<unk>')\n",
    "        \n",
    "        # Debugging prints\n",
    "        print(f\"Iteration {iteration}: Predicted token index = {sampled_token_index}, word = '{sampled_word}'\")\n",
    "        \n",
    "        # Append the word to the decoded sentence\n",
    "        if sampled_word != '<end>':\n",
    "            decoded_sentence.append(sampled_word)\n",
    "        \n",
    "        # Exit condition\n",
    "        if sampled_word == '<end>' or len(decoded_sentence) >= max_seq_length:\n",
    "            stop_condition = True\n",
    "        \n",
    "        # Update the target sequence (next input to the decoder)\n",
    "        target_seq = np.zeros((1, max_seq_length))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        \n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "        \n",
    "        iteration += 1  # increment iteration counter\n",
    "        \n",
    "    return ' '.join(decoded_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target tokenizer vocabulary size: 9521\n",
      "Special tokens in vocabulary: {'<start>': 9520, '<end>': 9521, '<unk>': 1}\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owendolan/opt/miniconda3/envs/neural-env/lib/python3.10/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_6', 'keras_tensor_13', 'keras_tensor_14']. Received: the structure of inputs=('*', '*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438ms/step\n",
      "Iteration 0: Predicted token index = 1, word = '<unk>'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Iteration 1: Predicted token index = 8, word = 'end'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Iteration 2: Predicted token index = 8, word = 'end'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Iteration 3: Predicted token index = 8, word = 'end'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Iteration 4: Predicted token index = 8, word = 'end'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Iteration 5: Predicted token index = 8, word = 'end'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Iteration 6: Predicted token index = 8, word = 'end'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Iteration 7: Predicted token index = 8, word = 'end'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Iteration 8: Predicted token index = 8, word = 'end'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Iteration 9: Predicted token index = 8, word = 'end'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Iteration 10: Predicted token index = 8, word = 'end'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Iteration 11: Predicted token index = 8, word = 'end'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Iteration 12: Predicted token index = 8, word = 'end'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Iteration 13: Predicted token index = 8, word = 'end'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Iteration 14: Predicted token index = 8, word = 'end'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Iteration 15: Predicted token index = 8, word = 'end'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Iteration 16: Predicted token index = 8, word = 'end'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Iteration 17: Predicted token index = 8, word = 'end'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Iteration 18: Predicted token index = 8, word = 'end'\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Iteration 19: Predicted token index = 8, word = 'end'\n",
      "Generated Summary: <unk> end end end end end end end end end end end end end end end end end end end\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_input = \"There are a lot of airplanes in the sky all flying around. Many people sit in the airplanes. The airplanes fly very fast.\"\n",
    "test_seq = pad_sequences(input_tokenizer.texts_to_sequences([test_input]), maxlen=max_seq_length, padding='post')\n",
    "\n",
    "# Print vocabulary info for debugging\n",
    "print(\"Target tokenizer vocabulary size:\", len(target_tokenizer.word_index))\n",
    "print(\"Special tokens in vocabulary:\", {token: target_tokenizer.word_index.get(token, 'Not found') for token in ['<start>', '<end>', '<unk>']})\n",
    "\n",
    "summary = decode_sequence(test_seq)\n",
    "print(\"Generated Summary:\", summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
